{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%run \"/content/drive/MyDrive/Research/Masters Thesis/V1/0. Parent Code.ipynb\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYqvXtthBrRE","executionInfo":{"status":"ok","timestamp":1667871250568,"user_tz":360,"elapsed":5646,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"34a795a9-a66d-4442-e0b3-a0ea195c3fcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","2401\n"]}]},{"cell_type":"markdown","source":["# 1. Loading Packages"],"metadata":{"id":"hdMzhiz_68eH"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","from sklearn.multiclass import OneVsRestClassifier\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","import seaborn as sns\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from statistics import mean\n","\n","import scipy\n","from scipy.sparse import csr_matrix"],"metadata":{"id":"WaSJEITtYuZt","executionInfo":{"status":"ok","timestamp":1667871250569,"user_tz":360,"elapsed":21,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12d0d050-de15-4997-d379-2d0559f1927a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["#2. Select the required texts from LinkedIn"],"metadata":{"id":"Rny5TBWqdh_h"}},{"cell_type":"code","source":["#Create labeled and unlabeled text list \n","\n","\n","# sex, name, degree_connection, current_location, current_industry, number_connection, \n","# edu1, edu2, edu3, edu4, edu5, edu6, \n","# number_skills, skills_list, skills_endorsement_pair, Intersts, summary,\n","# employment\n","\n","# Education is iteself and object with the following attributes\n","# SName, SLevel, SDates, SField, SDegree\n","\n","#Here employment is a list of jobs where each job contains information below \n","# [title, company_name, job_dates, job_location, job_summary, job_skills]\n","\n","\n","labeled_list = []\n","labeled_list_label = []\n","unlabeled_list = []\n","object_number =0\n","info_list_labeled = []\n","info_list_unlabeled = []\n","for ind in object_list:\n","\n","    for job in ind.employment:\n","        if job[4]!=None and job[5]!=None and len(job[5]) >= 5:\n","            split_description = job[4].split(\"\\n skill : \")\n","            if len(split_description) == 2 :\n","                info_list_labeled.append([ object_number ]+ job + [ind.skills_endorsement_pair])\n","                labeled_list.append(job[4])\n","                labeled_list_label.append(job[5])\n","            else:\n","                print(split_description)\n","                a = \"Error Check\" + 1\n","            \n","        elif  job[4]!=None: \n","            info_list_unlabeled.append([ object_number ]+ job)\n","            unlabeled_list.append(job[4])\n","    \n","    object_number = object_number  +1\n","\n","    # print(\"______________________\")\n","\n","print(len(labeled_list))\n","print(len(info_list_labeled))\n","print(len(unlabeled_list))\n","print(len(info_list_unlabeled))"],"metadata":{"id":"J7xpxclweY2X","executionInfo":{"status":"ok","timestamp":1667871250570,"user_tz":360,"elapsed":17,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67c2d0c5-ac06-4026-edad-2f38626a48e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1171\n","1171\n","14182\n","14182\n"]}]},{"cell_type":"code","source":["info_list_labeled[567]"],"metadata":{"id":"Bu2GKUeG1S-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Creating Y"],"metadata":{"id":"FkEVQGkx1THA"}},{"cell_type":"markdown","source":["## 3.1 Setting things up "],"metadata":{"id":"_ezdWWpiyhfk"}},{"cell_type":"markdown","source":["### 3.1.1 ONET Labels"],"metadata":{"id":"dwEGTAUfctsp"}},{"cell_type":"code","source":["ONET_df = pd.read_csv(main_link  + \"Input/final_ONET.csv\")\n","ONET_column_type = [\"Abilities\", \"Work Context\", \"Skills\", \"Knowledge\", \"Work Activities\",\"Description\", \t\"Rating\"]\n","selected_ONET_column = [x for x in ONET_df.columns if x.split(\"_\")[0] in ONET_column_type ]\n","\n","ONET_df = ONET_df[selected_ONET_column]"],"metadata":{"id":"LpUxkPbJ1Z4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Applying weight to the text descriptions \n","\n","def weigh_description(x):\n","  #Applying weight to different stated task \n","  #The descriptions are repeated 10 times \n","  description = (x[\"Description\"] + \" \\n \")*10\n","  #The task statment are repeated by the weight which are rounded to the nearest 10\n","  task_description = \"\"\n","  for i in x[\"Rating_task_values\"][2:-2].split(\"], [\"):\n","    i_split = i.split(\"', \")\n","    if len(i_split) != 2 : i_split = i.split('\", ')\n","    task_i = i_split[0][1:]\n","    rating_i = round(float(i_split[1])/10 ) \n","    task_description = task_description + \" \\n \" + (task_i  + \" \\n \")*rating_i \n","  #Output is a combination of the two\n","  output = description  + \" \\n \" + task_description\n","  return output \n","\n","ONET_df['ONET_text'] = ONET_df.apply(lambda x : weigh_description(x), axis = 1)\n","\n"],"metadata":{"id":"7tFcNfcJMrhs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.2 LinkedIn labeled discription labels"],"metadata":{"id":"MwSeR5n-cyT6"}},{"cell_type":"code","source":["#Create dictionary of LinkedIn skills to ONET skills from brute force sheet \n","brute_force = pd.read_excel(main_link  + \"Input/Brute force Final.xlsx\" )\n","\n","brute_force_values = brute_force[[\"Value _\" + str(i) for i in range(1,18)]].values.tolist()\n","brute_force_values = [[y for y in x if str(y) != \"nan\"] for x in brute_force_values]\n","brute_force_keys = [x.strip() for x in brute_force.LinkedIn_skills.values.tolist()]\n","\n"],"metadata":{"id":"0RI3F7Q7cOAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a dictionary of LinkedIn Skills to ONET skills \n","#Brute force only has three skill groups (Skills, abilities, knowledge), adding information on (Work Activities, Work Context) using their crosswalk\n","\n","\n","def Dict_WAC_crosswalk(df, c1, c2):\n","  WAC = c2.split(\" \")[0] + \" \" +c2.split(\" \")[1]     #WAC is either Work Context or Work Activities \n","  skill_or_ability = c1.split(\" \")[0]                 #This is either skills or abilities \n","  Dict_output = {}\n","\n","  for i in df[[c1, c2]].values.tolist():             \n","    item_to_add_value  = WAC+ \"_\"+i[1]                    #Example : Work Activities_Getting Information\n","    item_to_add_key = skill_or_ability + \"_\"+ i[0]             #Example: Skills_Reading Comprehension\n","\n","    if item_to_add_key in Dict_output.keys():     #If an entry for this skills or activity has already been created \n","      current_value = Dict_output[item_to_add_key]\n","      current_value.append(item_to_add_value )\n","      Dict_output[item_to_add_key] = current_value\n","    else:\n","      Dict_output[item_to_add_key] = [ item_to_add_value ]\n","\n","  output = Dict_output \n","  return output \n","\n","Skills_to_WA = Dict_WAC_crosswalk(  pd.read_excel(main_link  + \"Input/O*NET Input/Data_xlsx/Skills to Work Activities.xlsx\")      , \"Skills Element Name\", \"Work Activities Element Name\") \n","Skills_to_WC = Dict_WAC_crosswalk(pd.read_excel(main_link  + \"Input/O*NET Input/Data_xlsx/Skills to Work Context.xlsx\")           , \"Skills Element Name\", \"Work Context Element Name\" )\n","Abilities_to_WA = Dict_WAC_crosswalk(pd.read_excel(main_link  + \"Input/O*NET Input/Data_xlsx/Abilities to Work Activities.xlsx\")  , \"Abilities Element Name\",\"Work Activities Element Name\")\n","Abilities_to_WC = Dict_WAC_crosswalk(pd.read_excel(main_link  + \"Input/O*NET Input/Data_xlsx/Abilities to Work Context.xlsx\")     ,\"Abilities Element Name\",\"Work Context Element Name\" )\n","\n","#Zipping skills, abilities and knowledge into a dictionary\n","Dict_labeled_skills_ONET = dict(zip(brute_force_keys, brute_force_values))\n","\n","#Updating the values to included Work Actitivites and Work Context\n","WAC_dict_list = [Skills_to_WA, Skills_to_WC, Abilities_to_WA, Abilities_to_WC]\n","\n","print(list(Dict_labeled_skills_ONET.keys()))\n","\n","\n","for key in list(Dict_labeled_skills_ONET.keys())[0:1]:  #key here is Linkedin Skills \n","  current_value = Dict_labeled_skills_ONET[key]    #current_value is a list of linked skills, attitudes and knowledge \n","\n","  for item in Dict_labeled_skills_ONET[key]:       #here item is the individual linked skills, attitudes and knowledge\n","    for k in WAC_dict_list:                        #Now check if item is a key for any of the WA WC dictionaries\n","      if item in k.keys():\n","        current_value.extend(k[item])              #if item is in a dictionary add values of the WA WC dictionaries to current_value \n","  Dict_labeled_skills_ONET[key] = list(set(current_value))    #Finally update with this new value\n","\n","\n","#Dict_labeled_skills_ONET[\"Government\"]"],"metadata":{"id":"4Qb3JRf6pRXQ","executionInfo":{"status":"ok","timestamp":1667871252759,"user_tz":360,"elapsed":206,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"445bd127-490d-47b7-940f-e73743ce5437"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Business Development', 'Employee Benefits', 'Government', 'Organizational Development', 'Portfolio Management', 'Public Policy', 'Army', 'Call Centers', 'Cold Calling', 'Navy', 'Public Speaking', 'Sports', 'Physical Security', 'Security', 'Typing', 'Dreamweaver', 'Lean Six Sigma', 'ITIL', 'OS X', 'Copywriting', 'Scrum', 'Six Sigma', 'SDLC', 'Administration', 'Administrative Assistance', 'Administrative Assistants', 'Agile & Waterfall Methodologies', 'Agile Methodologies', 'Analysis', 'Analytical Skills', 'Benefits Administration', 'Blogging', 'Calendaring', 'Change Management', 'Cisco Technologies', 'Clinical Research', 'Collaborative Problem Solving', 'Community Outreach', 'Content Development', 'Content Management', 'Content Strategy', 'Copy Editing', 'Corporate Communications', 'Counterterrorism', 'Creative Direction', 'Creative Problem Solving', 'Creative Strategy', 'Creative Writing', 'Crisis Management', 'Critical Thinking', 'Data Analytics', 'Data Center', 'Data Science', 'Data Warehousing', 'Design Thinking', 'Digital Media', 'Digital Photography', 'Digital Strategy', 'Disaster Recovery', 'Documentation', 'DoD', 'Driving Results', 'E-Learning', 'Editing', 'Emergency Management', 'Employee Engagement', 'Employee Relations', 'EMR', 'English', 'Enrollment Management', 'Enterprise Architecture', 'Entertainment', 'Event Management', 'Event Planning', 'Executive Management', 'Executive Search', 'Fashion', 'Food & Beverage', 'Forecasting', 'Graphic Design', 'Graphics', 'Healthcare', 'Healthcare Information Technology', 'Healthcare Information Technology (HIT)', 'Hospitals', 'HR Policies', 'HTML5', 'Human Resources', 'Human Resources (HR)', 'Human Resources Information Systems (HRIS)', 'Information Security', 'Information Technology', 'Intelligence', 'Intelligence Analysis', 'Internal Communications', 'Internal Controls', 'International Relations', 'Internet Recruiting', 'Journalism', 'Laptops', 'Leadership', 'Lean Manufacturing', 'Legal Research', 'Legal Writing', 'Logo Design', 'Managed Care', 'Managed Services', 'Management', 'Management Consulting', 'Media Relations', 'Medical Terminology', 'Medicare', 'Meeting Planning', 'Military', 'Military Experience', 'Military Operations', 'Multimedia', 'Multitasking', 'National Security', 'Network Administration', 'Network Design', 'New Hire Orientations', 'Newsletters', 'Object-Oriented Programming (OOP)', 'Office Administration', 'Office Management', 'Onboarding', 'Operational Planning', 'Operations Management', 'Organization', 'Organization Skills', 'Organizational Effectiveness', 'Organizational Leadership', 'Phone Etiquette', 'Photography', 'Planning', 'Policy', 'Policy Analysis', 'Presentation Skills', 'Presentations', 'Press Releases', 'Problem Solving', 'Process Improvement', 'Process Scheduler', 'Product Development', 'Product Launch', 'Program Development', 'Program Evaluation', 'Program Management', 'Programming', 'Project Coordination', 'Proofreading', 'Proposal Writing', 'Public Relations', 'Qualitative Research', 'Quality Assurance', 'Quality Control', 'React.js', 'Records Management', 'Regression Testing', 'Report Writing', 'Reporting & Analysis', 'Requirements Gathering', 'Resume Writing', 'Scheduling', 'Screening Resumes', 'Security Clearance', 'Security Operations', 'Shell Scripting', 'Shipping', 'Skilled Multi-tasker', 'Social Media', 'Solution Selling', 'Sourcing', 'Spanish', 'Sports Management', 'Spreadsheets', 'Staffing Services', 'Start-ups', 'Statistics', 'Storytelling', 'Strategic Communications', 'Strategic Partnerships', 'Strategic Planning', 'Strategic Thinking', 'Strategy', 'Succession Planning', 'Talent Acquisition', 'Talent Management', 'Technical Recruiting', 'Technical Support', 'Technical Writing', 'Telecommunications', 'Television', 'Temporary Placement', 'Temporary Staffing', 'Test Planning', 'Testing', 'Time Management', 'Top Secret', 'Training Delivery', 'Travel Arrangements', 'Troubleshooting', 'User Interface Design', 'Veterans', 'Video', 'Visual Merchandising', 'VPN', 'Weapons', 'Web Content Writing', 'Web Design', 'Wellness', 'Wireless', 'Workshop Facilitation', 'Writing', 'Written Communication', 'Cashiering', 'Account Reconciliation', 'Accounting', 'Accounts Receivable', 'Auditing', 'B2B', 'Banking', 'Budget Management', 'Budgeting', 'Budgets', 'Business Analysis', 'Business Planning', 'Business Process Improvement', 'Business Strategy', 'Business-to-Business (B2B)', 'Competitive Analysis', 'Contract Management', 'Corporate Finance', 'Credit', 'Entrepreneurship', 'Finance', 'Financial Analysis', 'Financial Modeling', 'Financial Reporting', 'Financial Services', 'General Ledger', 'Government Contracting', 'Grant Writing', 'Grants', 'Investments', 'Invoicing', 'Loans', 'Market Analysis', 'Mortgage Lending', 'New Business Development', 'P&L Management', 'Payroll', 'Pricing', 'Pricing Strategy', 'Advertising', 'B2B Marketing', 'Brand Awareness', 'Brand Development', 'Brand Management', 'Branding & Identity', 'Consultative Selling', 'Content Marketing', 'Digital Marketing', 'Direct Marketing', 'Direct Sales', 'Fundraising', 'Inside Sales', 'Integrated Marketing', 'Lead Generation', 'Marketing', 'Marketing Communications', 'Marketing Management', 'Marketing Research', 'Marketing Strategy', 'Merchandising', 'Online Advertising', 'Online Marketing', 'Outside Sales', 'Product Marketing', 'Retail Sales', 'Sales', 'Sales & Marketing', 'Sales Operations', 'Sales Presentations', 'Sales Prospecting', 'Social Media Marketing', 'Sports Marketing', 'TCP/IP', 'DevOps', 'Automation', 'Computer Literacy', 'Computer Security', 'Cybersecurity', 'Data Management', 'Data Modeling', 'Data Visualization', 'Databases', 'Defense', 'Energy', 'Firewalls', 'IT Management', 'IT Operations', 'IT Service Management', 'IT Strategy', 'Mac', 'Machine Learning', 'Software Development', 'System Administration', 'Systems Engineering', 'Virtualization', 'Computer Repair', 'Computer Hardware', 'Construction', 'Electronics', 'Hardware', 'Infrastructure', 'Logistics', 'Manufacturing', 'Medical Devices', 'Military Logistics', 'Mobile Applications', 'Mobile Devices', 'Routers', 'Switches', 'Catering', 'Client Relations', 'Client Services', 'CRM', 'Customer Acquisition', 'Customer Engagement', 'Customer Loyalty', 'Customer Relationship Management (CRM)', 'Customer Success', 'Hospitality', 'Hospitality Industry', 'Hotels', 'Restaurants', 'Software as a Service (SaaS)', 'Help Desk Support', 'Building Relationships', 'Communication', 'Community Development', 'Conflict Resolution', 'Consulting', 'Continuous Improvement', 'Contract Negotiation', 'Cross-functional Team Leadership', 'Customer Experience', 'Customer Relations', 'Customer Retention', 'Customer Satisfaction', 'Customer Service', 'Customer Service Management', 'Customer Support', 'Diversity & Inclusion', 'Emotional Intelligence', 'Facilitation', 'Hiring', 'Information Assurance', 'Instructor-led Training', 'Interpersonal Communication', 'Interpersonal Skills', 'Interviewing', 'Interviews', 'Negotiation', 'Networking', 'People Management', 'Personal Development', 'Personnel Management', 'Recruiting', 'Relationship Building', 'Relationship Management', 'Servers', 'Social Networking', 'Staff Development', 'Supervisory Skills', 'Team Leadership', 'Team Management', 'Teamwork', 'Telephone Skills', 'User Acceptance Testing', 'User Experience', 'Volunteer Management', 'Business Relationship Management', 'E-commerce', 'Healthcare Management', 'Higher Education', 'Higher Education Administration', 'Hospitality Management', 'Hotel Management', 'Insurance', 'Integration', 'Key Account Management', 'Market Planning', 'Market Research', 'Non-profits', 'Nonprofit Organizations', 'Nonprofits', 'Procurement', 'Product Management', 'Profit', 'Purchasing', 'Real Estate', 'Resource Management', 'Restaurant Management', 'Retail', 'Risk Assessment', 'Risk Management', 'Selling', 'Small Business', 'Stakeholder Management', 'Store Management', 'Store Operations', 'Student Financial Aid', 'Supply Chain', 'Supply Chain Management', 'Trade Shows', 'U.S. Department of Defense', 'Warehouse Operations', 'Workforce Planning', 'Military Training', 'Academic Advising', 'Admissions', 'Adult Education', 'Career Counseling', 'Career Development', 'Classroom Management', 'Coaching', 'Coaching & Mentoring', 'College Recruiting', 'Curriculum Design', 'Curriculum Development', 'Differentiated Instruction', 'Distance Learning', 'Education', 'Educational Leadership', 'Educational Technology', 'Elementary Education', 'Employee Training', 'Instructional Design', 'Leadership Development', 'Learning Management Systems', 'Lesson Planning', 'LinkedIn Skill Assessment badge', 'Mentoring', 'Research', 'Student Affairs', 'Student Counseling', 'Student Development', 'Student Engagement', 'Student Recruiting', 'Teacher Training', 'Teaching', 'Team Building', 'Training', 'Training & Development', 'Tutoring', 'University Teaching']\n"]}]},{"cell_type":"code","source":["ONET_column_type = [\"Abilities\", \"Work Context\", \"Skills\", \"Knowledge\", \"Work Activities\"]\n","selected_ONET_column = [x for x in ONET_df.columns if x.split(\"_\")[0] in ONET_column_type ]\n"],"metadata":{"id":"6KXcZX5QmaH3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["skill_measures = []\n","\n","for job in info_list_labeled:\n","  # Initialize Dictionary\n","  Dict_skills_4dis_job =  dict(zip(selected_ONET_column, [0 for x in range(0,len(selected_ONET_column))])) \n","\n","  #Get endorsment information\n","  endorsments = [x[1] for x in job[-1]]\n","  highest_endorsment = max(endorsments )\n","  mean_endorsment = sum(endorsments ) / len(endorsments )\n","  skill_endorsment = dict(job[-1])\n","\n","  for skill in job[-2]:\n","    if skill in Dict_labeled_skills_ONET.keys(): #If this is a common enough skill\n","      ONET_skills = Dict_labeled_skills_ONET[skill]  #Get the linked ONET skills \n","      if skill in skill_endorsment.keys() and highest_endorsment >0: weight = 0.5 + (skill_endorsment[skill]+1) / (2 * highest_endorsment)\n","      else: weight = 0.74 \n","      for i in ONET_skills: \n","        if Dict_skills_4dis_job[i] < weight : Dict_skills_4dis_job[i] = weight \n","  skill_measures.append([job[5]]+[Dict_skills_4dis_job[x] for x in selected_ONET_column])\n"],"metadata":{"id":"j0ozT14tfnIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LinkedIn_labeled_skills_df = pd.DataFrame(skill_measures, columns = ['ONET_text']+selected_ONET_column )\n"],"metadata":{"id":"9d_YREB6vIBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.3 Final merge of total labeled data"],"metadata":{"id":"P-YGnR9Cc5AS"}},{"cell_type":"code","source":["total_labeled_data = pd.concat([ONET_df , LinkedIn_labeled_skills_df])\n"],"metadata":{"id":"VsNot_-scOD9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 Finding the best classifier of Y"],"metadata":{"id":"_D4z62-FcOYe"}},{"cell_type":"markdown","source":["Use ONET to train and labeled LinkedIn to test"],"metadata":{"id":"ws2nCUSfdmud"}},{"cell_type":"code","source":["LinkedIn_labeled_skills_df"],"metadata":{"id":"qcYBhFf-uLkm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Input = ONET_df, LinkedIn_labeled_skills_df\n","#Output = Dict of accuracy of each classifier\n","\n","from collections import Counter\n","\n","\n","def test_train_df(df_train, df_test):\n","\n","  test, train = df_test ,  df_train\n","  X_train = train.ONET_text\n","  X_test = test.ONET_text\n","\n","  return test, train, X_test, X_train\n","\n","\n","\n","def change_to_percentile(x):\n","    if x<0.25: output = \"0.25\" \n","    elif x<0.50: output = \"0.50\"\n","    elif x<0.75: output = \"0.75\"\n","    else: output = \"1\"\n","    return output\n","\n","def specify_pipelines():\n","  #Multinomial Naives Bayes's Pipleline\n","  NB_pipeline = Pipeline([\n","                  ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 2))),\n","                  ('clf', OneVsRestClassifier(MultinomialNB(\n","                      fit_prior=True, class_prior=None))),\n","              ])\n","  #Linear Support Vector Classification's Pipeline\n","  SVC_pipeline = Pipeline([\n","                  ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 2))),\n","                  ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n","              ])\n","  #Multinomial Logistic's Pipeline\n","  LogReg_pipeline = Pipeline([\n","                  ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 2))),\n","                  ('clf', OneVsRestClassifier(LogisticRegression(solver='sag', max_iter = 500), n_jobs=1)),\n","              ])\n","  return NB_pipeline, SVC_pipeline, LogReg_pipeline\n","\n","\n","\n","\n","\n","\n","def find_best_classifier(ONET_df, LinkedIn_labeled_skills_df, ONET_skills_column):\n","\n","  #set pipelines \n","  NB_pipeline, SVC_pipeline,  LogReg_pipeline = specify_pipelines()\n","\n","  #Find test accuracy \n","  test_accuracy_NB ,test_accuracy_SVC ,test_accuracy_Logistic = [], [], []\n","  a = 0\n","  \n","  Y_skills_list = []\n","  for skills in ONET_skills_column:\n","      \n","      #create test train for this skill\n","      count = Counter(LinkedIn_labeled_skills_df[skills].values.tolist()).most_common(4)\n","      if len(count)>1 and (count[0][1] < 700):\n","        print(skills, count)\n","        LinkedIn_train, LinkedIn_test = train_test_split(LinkedIn_labeled_skills_df, random_state=42, test_size=0.33, shuffle=True)\n","        test, train, X_test, X_train = test_train_df(     pd.concat([ONET_df , LinkedIn_train])   ,  LinkedIn_test )\n","        \n","        print(a)\n","        a =a +1\n","        print('... Processing {}'.format(skills))\n","\n","        # train the model using X_dtm & y\n","        y = np.array([change_to_percentile(xi) for xi in train[skills]])\n","        \n","        NB_pipeline.fit(X_train,  y  )\n","        SVC_pipeline.fit(X_train,  y  )\n","        LogReg_pipeline.fit(X_train, y)\n","\n","      \n","        # compute the testing accuracy\n","        prediction_NB = NB_pipeline.predict(X_test)\n","        prediction_SVC = SVC_pipeline.predict(X_test)\n","        prediction_LogReg = LogReg_pipeline.predict(X_test)\n","\n","        y = np.array([change_to_percentile(xi) for xi in test[skills]])\n","\n","        NB_accuracy, SVC_accuracy , Logstic_accuracy = accuracy_score(y, prediction_NB), accuracy_score(y, prediction_SVC), accuracy_score(y, prediction_LogReg)\n","        print('Test accuracy for NB is {}'.format(NB_accuracy))\n","        print('Test accuracy for SVC is {}'.format(SVC_accuracy ))\n","        print('Test accuracy for Logistic is {}'.format(Logstic_accuracy))\n","\n","        test_accuracy_NB.append(NB_accuracy)\n","        test_accuracy_SVC.append(SVC_accuracy)\n","        test_accuracy_Logistic.append(Logstic_accuracy)\n","        Y_skills_list.append(skills)\n","\n","  print(\"                 \")\n","\n","  Dict_NB_accuracy = dict(zip(Y_skills_list, test_accuracy_NB))\n","  Dict_SVC_accuracy = dict(zip(Y_skills_list, test_accuracy_SVC))\n","  Dict_Logistic_accuracy = dict(zip(Y_skills_list, test_accuracy_Logistic))\n","  \n","  return Dict_NB_accuracy, Dict_SVC_accuracy, Dict_Logistic_accuracy\n","\n","\n","\n","\n","\n","\n","#Skills to consider\n","ONET_column_type_skills = [\"Abilities\", \"Work Context\", \"Skills\", \"Knowledge\", \"Work Activities\"]\n","ONET_skills_column = [x for x in ONET_df.columns if x.split(\"_\")[0] in ONET_column_type_skills]\n","\n","\n","Dict_NB_accuracy , Dict_SVC_accuracy, Dict_Logistic_accuracy = find_best_classifier(ONET_df, LinkedIn_labeled_skills_df, ONET_skills_column)\n","\n","print(\"NB -> \" + str(mean(Dict_NB_accuracy.values())))\n","print(\"SVC -> \" + str(mean(Dict_SVC_accuracy.values())))\n","print(\"Logistic -> \" + str(mean(Dict_Logistic_accuracy.values())))"],"metadata":{"id":"fa9h4q9d6tuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667871371061,"user_tz":360,"elapsed":118135,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"c3578337-3030-4640-8189-e80ef735d58f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Abilities_Inductive Reasoning [(0.0, 485), (0.74, 75), (1.0, 47), (0.5714285714285714, 42)]\n","0\n","... Processing Abilities_Inductive Reasoning\n","Test accuracy for NB is 0.4728682170542636\n","Test accuracy for SVC is 0.6511627906976745\n","Test accuracy for Logistic is 0.5658914728682171\n","Abilities_Mathematical Reasoning [(0.0, 689), (0.74, 50), (1.0, 33), (0.5714285714285714, 27)]\n","1\n","... Processing Abilities_Mathematical Reasoning\n","Test accuracy for NB is 0.6873385012919897\n","Test accuracy for SVC is 0.7596899224806202\n","Test accuracy for Logistic is 0.7416020671834626\n","Abilities_Number Facility [(0.0, 563), (0.74, 72), (1.0, 45), (0.5714285714285714, 33)]\n","2\n","... Processing Abilities_Number Facility\n","Test accuracy for NB is 0.6434108527131783\n","Test accuracy for SVC is 0.7441860465116279\n","Test accuracy for Logistic is 0.7080103359173127\n","Abilities_Oral Comprehension [(0.0, 428), (0.74, 93), (1.0, 56), (0.5714285714285714, 49)]\n","3\n","... Processing Abilities_Oral Comprehension\n","Test accuracy for NB is 0.4935400516795866\n","Test accuracy for SVC is 0.7054263565891473\n","Test accuracy for Logistic is 0.5891472868217055\n","Abilities_Oral Expression [(0.0, 460), (0.74, 96), (1.0, 54), (0.75, 47)]\n","4\n","... Processing Abilities_Oral Expression\n","Test accuracy for NB is 0.5064599483204134\n","Test accuracy for SVC is 0.7131782945736435\n","Test accuracy for Logistic is 0.6149870801033591\n","Abilities_Speech Clarity [(0.0, 514), (0.74, 94), (1.0, 53), (0.5714285714285714, 43)]\n","5\n","... Processing Abilities_Speech Clarity\n","Test accuracy for NB is 0.5297157622739018\n","Test accuracy for SVC is 0.7183462532299741\n","Test accuracy for Logistic is 0.6692506459948321\n","Abilities_Speech Recognition [(0.0, 407), (0.74, 89), (1.0, 65), (0.5714285714285714, 51)]\n","6\n","... Processing Abilities_Speech Recognition\n","Test accuracy for NB is 0.524547803617571\n","Test accuracy for SVC is 0.7080103359173127\n","Test accuracy for Logistic is 0.6020671834625323\n","Skills_Active Listening [(0.0, 490), (0.74, 84), (0.5714285714285714, 48), (1.0, 48)]\n","7\n","... Processing Skills_Active Listening\n","Test accuracy for NB is 0.4780361757105943\n","Test accuracy for SVC is 0.7028423772609819\n","Test accuracy for Logistic is 0.5839793281653747\n","Skills_Complex Problem Solving [(0.0, 696), (0.74, 65), (0.5714285714285714, 40), (1.0, 27)]\n","8\n","... Processing Skills_Complex Problem Solving\n","Test accuracy for NB is 0.6408268733850129\n","Test accuracy for SVC is 0.7855297157622739\n","Test accuracy for Logistic is 0.7441860465116279\n","Skills_Social Perceptiveness [(0.0, 669), (0.74, 67), (1.0, 48), (0.5714285714285714, 36)]\n","9\n","... Processing Skills_Social Perceptiveness\n","Test accuracy for NB is 0.6770025839793282\n","Test accuracy for SVC is 0.7674418604651163\n","Test accuracy for Logistic is 0.7467700258397932\n","Skills_Speaking [(0.0, 514), (0.74, 94), (1.0, 53), (0.5714285714285714, 43)]\n","10\n","... Processing Skills_Speaking\n","Test accuracy for NB is 0.4935400516795866\n","Test accuracy for SVC is 0.6925064599483204\n","Test accuracy for Logistic is 0.6253229974160207\n","                 \n","NB -> 0.5588442565186751\n","SVC -> 0.7225745830396993\n","Logistic -> 0.6537467700258398\n"]}]},{"cell_type":"markdown","source":["## 3.3 Finally Creating the Y"],"metadata":{"id":"ptP_xQvv0OQV"}},{"cell_type":"code","source":["print(len(unlabeled_list))\n","print(len(labeled_list))\n","\n","\n","#Linear Support Vector Classification's Pipeline\n","SVC_pipeline = Pipeline([\n","                ('tfidf', TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))),\n","                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n","            ])\n","\n","Y_predicted = [unlabeled_list]\n","a=0\n","Y_skills_list = []\n","for skills in ONET_skills_column:\n","   \n","    if skills in Dict_SVC_accuracy.keys():\n","      test, train, X_test, X_train = test_train_df( pd.concat([ONET_df , LinkedIn_labeled_skills_df])   ,  LinkedIn_labeled_skills_df )   #Here test is not used, just passing for the function\n","      y = np.array([change_to_percentile(xi) for xi in train[skills]])\n","      SVC_pipeline.fit(X_train,  y  )\n","      prediction_SVC = SVC_pipeline.predict(unlabeled_list)\n","      Y_predicted.append(prediction_SVC)\n","      Y_skills_list.append(skills)\n","\n","\n","Y_values = []\n","for i in range(0,len(Y_predicted[0])):\n","    row = []\n","    for j in Y_predicted: row.append(j[i])\n","    Y_values.append(row)\n","\n","\n","Y_unlabeled = pd.DataFrame(Y_values, columns =  [\"LinkedIn_Text\"] + Y_skills_list  ) \n","Y_labeled = LinkedIn_labeled_skills_df[[\"ONET_text\"] + Y_skills_list]\n","Y_labeled = Y_labeled.rename(columns={\"ONET_text\": \"LinkedIn_Text\"}) \n","\n","\n","# with pd.ExcelWriter(main_link + 'Input/Y_df.xlsx') as writer:  \n","#     Y.to_excel(writer, sheet_name='Sheet_name_1')\n"],"metadata":{"id":"Y-rKJSxGbQa6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667871429653,"user_tz":360,"elapsed":58602,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"83bc8a57-c266-47c1-da57-65105851c971"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["14182\n","1171\n"]}]},{"cell_type":"code","source":["Y  = pd.concat([Y_unlabeled  , Y_labeled]) \n","with pd.ExcelWriter(main_link + 'Input/Y_df.xlsx') as writer:  \n","    Y.to_excel(writer, sheet_name='Sheet_name_1')\n","\n"],"metadata":{"id":"esm_L0RV7FCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_df = pd.read_csv(main_link + 'Input/Y_df.csv')[[\"Text\"] + ONET_skills_column].rename(columns={\"Text\": \"LinkedIn_Text\"})\n","Y = csr_matrix(Y_df[ONET_skills_column].values)"],"metadata":{"id":"zsbX0yAY4C8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"su5HCEub7j8W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How good is the classifier? Test using the training data"],"metadata":{"id":"91y0tekvinXA"}},{"cell_type":"code","source":["print(len(ONET_skills_column))"],"metadata":{"id":"ObKNrgjljqyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, test = train_test_split(total_labeled_data, random_state=42, test_size=0.33, shuffle=True)\n","test = test[test[\"ONET_text\"].isin(LinkedIn_labeled_skills_df['ONET_text'].values.tolist())]\n","\n","X_train = train.ONET_text\n","X_test = test.ONET_text\n","\n","print(len(X_test))\n","test_accuracy_NB ,test_accuracy_SVC ,test_accuracy_Logistic = [], [], []\n","a = 0\n","\n","for skills in ONET_skills_column:\n","    print(a)\n","    a =a +1\n","    print('... Processing {}'.format(skills))\n","\n","    # train the model using X_dtm & y\n","    y = np.array([change_to_percentile(xi) for xi in train[skills]])\n","    \n","    SVC_pipeline.fit(X_train,  y  )\n","\n","\n","    # compute the testing accuracy\n","    prediction_SVC = SVC_pipeline.predict(X_test)\n","\n","    y = np.array([change_to_percentile(xi) for xi in test[skills]])\n","\n","    SVC_accuracy = accuracy_score(y, prediction_SVC)\n","    print('Test accuracy for SVC is {}'.format(SVC_accuracy ))\n","\n","\n","    test_accuracy_SVC.append(SVC_accuracy)\n","\n","    print(\"                 \")\n","\n","\n","print(\"SVC -> \" + str(mean(test_accuracy_SVC)))\n","\n"],"metadata":{"id":"5KakOZx94FSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr = [1,4,5,7]\n","arr = np.asarray(test_accuracy_SVC)\n","\n","min = np.amin(arr)\n","max = np.amax(arr)\n","range = np.ptp(arr)\n","variance = np.var(arr)\n","sd = np.std(arr)\n"," \n","print(\"Array =\", arr)\n","print(\"Measures of Dispersion\")\n","print(\"Minimum =\", min)\n","print(\"Maximum =\", max)\n","print(\"Range =\", range)\n","print(\"Variance =\", variance)\n","print(\"Standard Deviation =\", sd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yo9D3v8W5HA1","executionInfo":{"status":"ok","timestamp":1667703962827,"user_tz":300,"elapsed":89,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"8ed0f4f1-27ea-4f59-ef17-88e011050445"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Array = [1 4 5 7]\n","Measures of Dispersion\n","Minimum = 1\n","Maximum = 7\n","Range = 6\n","Variance = 4.6875\n","Standard Deviation = 2.165063509461097\n"]}]},{"cell_type":"markdown","source":["# MLSI"],"metadata":{"id":"Va4AkzJEjOsV"}},{"cell_type":"markdown","source":["# 4. Creating X"],"metadata":{"id":"UDlel5Y_UYnW"}},{"cell_type":"code","source":["import scipy\n","from scipy.sparse import csr_matrix"],"metadata":{"id":"_o32uVWd_VDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tfidf_transformer=TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2)) \n","# X = tfidf_transformer.fit_transform(unlabeled_list)\n","# print(type(X))\n","\n","count_vector_transformer = CountVectorizer(stop_words=\"english\", ngram_range=(1,2)) \n","X = count_vector_transformer.fit_transform(unlabeled_list)\n","print(type(X))\n","\n","X.get_shape()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-oKOiCMUm47","executionInfo":{"status":"ok","timestamp":1667877269400,"user_tz":360,"elapsed":4747,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"6a21daaf-7c2b-44a7-c621-b6b4de2d4ecf"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'scipy.sparse.csr.csr_matrix'>\n"]},{"output_type":"execute_result","data":{"text/plain":["(14182, 498067)"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# print(X[700])"],"metadata":{"id":"CQyfEHrUQFd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = dict(zip(count_vector_transformer.get_feature_names_out(), np.squeeze(np.asarray(X.sum(axis=0))).tolist() ))"],"metadata":{"id":"JTix7sc5Lkos","executionInfo":{"status":"ok","timestamp":1667877342501,"user_tz":360,"elapsed":645,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["count_vector_transformer.get_feature_names_out()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"3RnFcJRzUm-z","executionInfo":{"status":"ok","timestamp":1667877420613,"user_tz":360,"elapsed":608,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"fb0fce14-e99f-4520-c80f-02d19a6b2222"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'40 active'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["a[\"40 active\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1V0r6GdoPOEW","executionInfo":{"status":"ok","timestamp":1667877432512,"user_tz":360,"elapsed":161,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"712e9450-f677-4bfa-8de9-fee026fa1a2b"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["b = [x for x in count_vector_transformer.get_feature_names_out() if a[x] > 2]"],"metadata":{"id":"qfnUQ_RvPhpJ","executionInfo":{"status":"ok","timestamp":1667903050903,"user_tz":360,"elapsed":609,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["print(len(b))\n","print(b[1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyX2t_9MPrrY","executionInfo":{"status":"ok","timestamp":1667903051903,"user_tz":360,"elapsed":147,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"8711c7a6-fb0a-4668-b726-5a41b67e5490"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["68758\n","4361 managerial\n"]}]},{"cell_type":"code","source":["a[\"000 create\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9COZ6oKCP2Oh","executionInfo":{"status":"ok","timestamp":1667877544416,"user_tz":360,"elapsed":176,"user":{"displayName":"Bikalpa Baniya","userId":"07767760245515540795"}},"outputId":"61bcc165-6fae-457f-88da-dd5e917769ad"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","source":["# 5. MLSI Function "],"metadata":{"id":"GrwG-Q40J-h-"}},{"cell_type":"code","source":["from scipy.sparse.linalg import eigs\n","from scipy.sparse.linalg import inv\n","import time"],"metadata":{"id":"J5loWqcnuMc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_M(K_x, C, gamma):\n","\n","  t0 = time.time() # time\n","  C_inv = inv(C)\n","\n","  t1 = time.time() # time\n","  print(\"Getting  C inverse \"+str(t1- t0)) # time\n","\n","  output = K_x * C_inv * K_x + gamma * K_x\n","  t2 = time.time() # time\n","  print(\"Getting  M \"+str(t2- t1)) # time\n","  return output \n","\n","def GEV_solver(K_x,K_y,C, gamma, K):\n","  #Solve the generalized eigenvalue problem K_x^2 alpha = lambda [K_x C^{-1} K_x + gamma * K_x] alpha \n","\n","  t0 = time.time() # time\n","  K_x_sqr = K_x * K_x \n","  t1 = time.time() # time\n","  print(\"Squaring \"+str(t1- t0)) #time\n","\n","  M_1 = get_M(K_x, C, gamma)\n","\n","  t2 = time.time() # time\n","  vals, vecs = eigs(K_x_sqr , k=K, M = M_1)\n","  \n","  t3 = time.time() # time\n","  print(\"Solving eigenvalue problems \"+str(t3- t2)) # time\n","  return vals, vecs\n","\n","def get_MLSI_index(X, Y , beta, gamma, K):\n","  t0 = time.time() # time\n","  K_x = X * csr_matrix.transpose(X)\n","  K_y = Y * csr_matrix.transpose(Y)\n","  C = (1-beta) * K_x + beta * K_y \n","\n","  t1 = time.time() # time\n","  print(\"Step one \"+str(t1- t0)) #time\n","\n","  eigenvalues,  eigenvectors = GEV_solver(K_x,K_y,C, gamma, K)\n","\n","  print(len(eigenvalues))\n","  print(len(eigenvectors))\n","  return eigenvalues,  eigenvectors \n","\n","\n","random_sample = sample(range(0,14182),1000)\n","a,b = get_MLSI_index(X.tocsr()[random_sample ,:], Y.tocsr()[random_sample,:] , 0.5, 0, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9JIXQqYH8fZ","executionInfo":{"status":"ok","timestamp":1667161890154,"user_tz":300,"elapsed":6724,"user":{"displayName":"BIKALPA BANIYA","userId":"00410341000997255905"}},"outputId":"b38c29bf-0095-4c23-e748-fff5ac6dbb1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step one 0.39394640922546387\n","Squaring 1.4939074516296387\n","Getting  C inverse 1.2770159244537354\n","Getting  M 3.0300114154815674\n","Solving eigenvalue problems 0.386918306350708\n","6\n","1000\n"]}]},{"cell_type":"code","source":["len(b[0])"],"metadata":{"id":"kA4rReRV1TWS","executionInfo":{"status":"ok","timestamp":1667161949039,"user_tz":300,"elapsed":4,"user":{"displayName":"BIKALPA BANIYA","userId":"00410341000997255905"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44bbe7e9-6c7d-44a9-e0dd-595a2567ef78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["\n","from random import sample\n","  \n","\n","  \n","print(sample(range(0,100),3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARFViQNH1TZM","executionInfo":{"status":"ok","timestamp":1667161874503,"user_tz":300,"elapsed":17,"user":{"displayName":"BIKALPA BANIYA","userId":"00410341000997255905"}},"outputId":"87aab00a-3cb9-434f-df50-c1e9b18aaf1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[44, 0, 45]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pgBms4uJ1TcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-oq9viEw1Te-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(type(X))\n","# print(X.get_shape())\n","# X_T = csr_matrix.transpose(X)\n","# print(X_T.get_shape())\n","# print(type(X_T))\n","\n","# beta = 0.5\n","\n","# K_x = X * X_T\n","# print(type(K_x ))\n","# print(K_x.get_shape())\n","\n","# # print(K_x)\n","# C = K_x * K_x\n","# print(\"----------------------------\")\n","# # print(C)\n","# print(C.get_shape())\n","# print(type(C))"],"metadata":{"id":"AcRE71sdHue1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(type(Y))\n","# print(Y.get_shape())\n","# Y_T = csr_matrix.transpose(Y)\n","# print(Y_T.get_shape())\n","# print(type(Y_T))\n","\n","# YY_T = Y * Y_T\n","# print(YY_T.get_shape())"],"metadata":{"id":"yGs8OKmSH20z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(type(YY_T))"],"metadata":{"id":"YN3bKbB1jlYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YXD_KCaijm9i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","  \n","# Create first csr matrix A\n","row_A = np.array([0, 0, 1, 2 ])\n","col_A = np.array([0, 1, 0, 1])\n","data_A = np.array([4, 3, 8, 9])\n","  \n","csrMatrix_A = csr_matrix((data_A, (row_A, col_A)),\n","                        shape = (3, 3))\n","  \n","# print first csr matrix\n","print(\"first csr matrix: \\n\", csrMatrix_A.toarray())\n","  \n","# Create second csr matrix B\n","row_B = np.array([0, 1, 1, 2 ])\n","col_B = np.array([0, 0, 1, 0])\n","data_B = np.array([7, 2, 5, 1])\n","  \n","csrMatrix_B = csr_matrix((data_B, (row_B, col_B)),\n","                        shape = (3, 3))\n","  \n","# print second scr matrix\n","print(\"second csr matrix:\\n\", csrMatrix_B.toarray())\n","\n","print(type(csrMatrix_A )) \n","print(type(csrMatrix_B )) \n","# Multiply these matrices\n","sparseMatrix_AB = 2 * csrMatrix_A  + 3 * csrMatrix_B \n","  \n","# print resultant matrix\n","print(\"Product Sparse Matrix:\\n\",sparseMatrix_AB.toarray() )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NodKcE9GomRg","executionInfo":{"status":"ok","timestamp":1667161874894,"user_tz":300,"elapsed":13,"user":{"displayName":"BIKALPA BANIYA","userId":"00410341000997255905"}},"outputId":"108fb36f-afb5-4f12-99d5-d830f6a0007c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["first csr matrix: \n"," [[4 3 0]\n"," [8 0 0]\n"," [0 9 0]]\n","second csr matrix:\n"," [[7 0 0]\n"," [2 5 0]\n"," [1 0 0]]\n","<class 'scipy.sparse.csr.csr_matrix'>\n","<class 'scipy.sparse.csr.csr_matrix'>\n","Product Sparse Matrix:\n"," [[29  6  0]\n"," [22 15  0]\n"," [ 3 18  0]]\n"]}]},{"cell_type":"code","source":["sparseMatrix_AB.tocsr()[sample(range(0,3),2),:].todense()\n","# sparseMatrix_AB.tocsr()[sample(range(0,3),1),:].get_shape()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q124SlzuomUE","executionInfo":{"status":"ok","timestamp":1667161874894,"user_tz":300,"elapsed":12,"user":{"displayName":"BIKALPA BANIYA","userId":"00410341000997255905"}},"outputId":"cc7044e0-aed1-4f4a-8779-83b46f355d23"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["matrix([[ 3, 18,  0],\n","        [22, 15,  0]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":[],"metadata":{"id":"CeUDM1QO1Obk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["hdMzhiz_68eH","dwEGTAUfctsp","MwSeR5n-cyT6","lQ98TR3Vyauh"],"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}